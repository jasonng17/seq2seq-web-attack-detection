{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darklord/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/darklord/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "from colorama import Fore\n",
    "from sklearn.metrics import auc, roc_curve, precision_score, recall_score\n",
    "\n",
    "from utils.vocab import Vocabulary\n",
    "from utils.reader import Data\n",
    "from utils.utils import print_progress, create_checkpoints_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main model parameters:\n",
    "- *batch_size* - the number of samples in a batch\n",
    "- *embed_size* - the dimension of embedding space (should be less than vocabulary size)\n",
    "- *hidden_size* - the number of hidden states in lstm \n",
    "- *num_layers* - the number of lstm blocks\n",
    "- *checkpoints* - path to checkpoint directory\n",
    "- *std_factor* - the number of stds that is used for defining a model threshold\n",
    "- *dropout* - the probability that each element is kept\n",
    "- *vocab* - the Vocabulary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 21991 samples\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"batch_size\": 128,\n",
    "    \"embed_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"checkpoints\": \"./checkpoints/\",\n",
    "    \"std_factor\": 6.,\n",
    "    \"dropout\": 0.7,\n",
    "}\n",
    "\n",
    "path_normal_data = \"datasets/vulnbank_train.txt\"\n",
    "path_anomaly_data = \"datasets/vulnbank_anomaly.txt\"\n",
    "\n",
    "create_checkpoints_dir(params[\"checkpoints\"])\n",
    "\n",
    "vocab = Vocabulary()\n",
    "params[\"vocab\"] = vocab\n",
    "\n",
    "d = Data(path_normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the code the Sequence-to-Sequence model for determining anomalies is defined.  \n",
    "The same sequences are fed to the input and output of the model. So the model learns to reconstruct them. At the stage of training and validation, only valid samples are submitted to the model. The validation phase is needed in order to initialize the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq():\n",
    "    def __init__(self, args):\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.batch_size = tf.placeholder(tf.int32, [], name='batch_size')\n",
    "        self.max_seq_len = tf.placeholder(tf.int32, [], name='max_seq_len')\n",
    "        self.inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "        self.targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "        self.lengths = tf.placeholder(tf.int32, [None, ], name='lengths')\n",
    "        self.dropout = tf.placeholder(tf.float32, name='dropout')\n",
    "        \n",
    "        self.num_layers = args['num_layers']\n",
    "        self.hidden_size = args['hidden_size']\n",
    "        self.vocab = args['vocab']\n",
    "\n",
    "        dec_input = self._process_decoder_input(\n",
    "            self.targets,\n",
    "            self.vocab.vocab,\n",
    "            tf.to_int32(self.batch_size))\n",
    "\n",
    "        vocab_size = len(self.vocab.vocab)\n",
    "\n",
    "        # Embeddings for inputs\n",
    "        embed_initializer = tf.random_uniform_initializer(-np.sqrt(3), np.sqrt(3))\n",
    "\n",
    "        with tf.variable_scope('embedding'):\n",
    "            embeds = tf.get_variable(\n",
    "                'embed_matrix',\n",
    "                [vocab_size, args['embed_size']],\n",
    "                initializer=embed_initializer,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            enc_embed_input = tf.nn.embedding_lookup(embeds, self.inputs)\n",
    "            \n",
    "        enc_state = self._encoder(enc_embed_input)\n",
    "        \n",
    "        # Embeddings for outputs\n",
    "        with tf.variable_scope('embedding', reuse=True):\n",
    "            dec_embed_input = tf.nn.embedding_lookup(embeds, dec_input)\n",
    "\n",
    "        dec_outputs = self._decoder(enc_state, dec_embed_input)\n",
    "\n",
    "        weight, bias = self._weight_and_bias(args['hidden_size'], vocab_size)\n",
    "        outputs = tf.reshape(dec_outputs[0].rnn_output, [-1, args['hidden_size']])\n",
    "        logits = tf.matmul(outputs, weight) + bias\n",
    "\n",
    "        logits = tf.reshape(logits, [-1, self.max_seq_len, vocab_size], name='logits')\n",
    "        self.probs = tf.nn.softmax(logits, name='probs')\n",
    "        self.decoder_outputs = tf.argmax(logits, axis=2)\n",
    "\n",
    "        self.cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits,\n",
    "            labels=self.targets,\n",
    "            name='cross_entropy')\n",
    "        self.batch_loss = tf.identity(tf.reduce_mean(self.cross_entropy, axis=1), name='batch_loss')\n",
    "        self.loss = tf.reduce_mean(self.cross_entropy)\n",
    "\n",
    "        self.train_optimizer = self._optimizer(self.loss)\n",
    "\n",
    "        # Saver\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def _encoder(self, enc_embed_input):\n",
    "        \"\"\"\n",
    "        Adds an encoder to the model architecture.\n",
    "        \"\"\"\n",
    "        cells = [self._lstm_cell(self.hidden_size) for _ in range(self.num_layers)]\n",
    "        multilstm = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        _, enc_state = tf.nn.dynamic_rnn(\n",
    "            multilstm,\n",
    "            enc_embed_input,\n",
    "            sequence_length=self.lengths,\n",
    "            swap_memory=True,\n",
    "            dtype=tf.float32)\n",
    "        \n",
    "        return enc_state\n",
    "    \n",
    "    def _decoder(self, enc_state, dec_embed_input):\n",
    "        \"\"\"\n",
    "        Adds a decoder to the model architecture.\n",
    "        \"\"\"\n",
    "        output_lengths = tf.ones([self.batch_size], tf.int32) * self.max_seq_len\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            dec_embed_input,\n",
    "            output_lengths,\n",
    "            time_major=False)\n",
    "\n",
    "        cells = [self._lstm_cell(self.hidden_size) for _ in range(self.num_layers)]\n",
    "        dec_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, helper, enc_state)\n",
    "\n",
    "        dec_outputs = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder,\n",
    "            output_time_major=False,\n",
    "            impute_finished=True,\n",
    "            maximum_iterations=self.max_seq_len, swap_memory=True)\n",
    "        \n",
    "        return dec_outputs\n",
    "    \n",
    "    def _optimizer(self, loss,):\n",
    "        \"\"\"\n",
    "        Optimizes weights given a loss. \n",
    "        \"\"\"\n",
    "        def _learning_rate_decay_fn(learning_rate, global_step):\n",
    "            return tf.train.exponential_decay(learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n",
    "\n",
    "        starting_lr = 0.001\n",
    "        starting_global_step = tf.Variable(0, trainable=False)\n",
    "        optimizer = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=starting_global_step,\n",
    "            learning_rate=starting_lr,\n",
    "            optimizer=tf.train.AdamOptimizer,\n",
    "            learning_rate_decay_fn=lambda lr, gs: _learning_rate_decay_fn(lr, gs),\n",
    "            clip_gradients=5.0)\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "    def _process_decoder_input(self, target_data, char_to_code, batch_size):\n",
    "        \"\"\"\n",
    "        Concatenates the <GO> to the begining of each batch.\n",
    "        \"\"\"\n",
    "        ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "        dec_input = tf.concat([tf.fill([batch_size, 1], char_to_code['<GO>']), ending], 1)\n",
    "\n",
    "        return dec_input\n",
    "\n",
    "    def _lstm_cell(self, hidden_size):\n",
    "        \"\"\"\n",
    "        Returns LSTM cell with dropout.\n",
    "        \"\"\"\n",
    "        cell = tf.contrib.rnn.LSTMCell(\n",
    "            hidden_size,\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=self.dropout)\n",
    "\n",
    "        return cell\n",
    "\n",
    "    def _weight_and_bias(self, in_size, out_size):\n",
    "        \"\"\"\n",
    "        Initializes weights and biases.\n",
    "        \"\"\"\n",
    "        weight = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.01))\n",
    "        bias = tf.Variable(tf.constant(1., shape=[out_size]))\n",
    "\n",
    "        return weight, bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\n",
    "    def __init__(self, batch_size, checkpoints_path, dropout):\n",
    "        self.batch_size = batch_size\n",
    "        self.checkpoints = checkpoints_path\n",
    "        self.path_to_graph = checkpoints_path + 'seq2seq'\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def train(self, model, train_data, train_size, num_steps, num_epochs, min_loss=0.3):\n",
    "        \"\"\"\n",
    "        Trains a given model architecture with given train data.\n",
    "        \"\"\"\n",
    "        tf.set_random_seed(1234)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            total_loss = []\n",
    "            timings = []\n",
    "            steps_per_epoch = int(train_size / self.batch_size)\n",
    "            num_epoch = 1\n",
    "            \n",
    "            for step in range(1, num_steps):\n",
    "                beg_t = timeit.default_timer()\n",
    "                #X, L = train_data.next()\n",
    "                X, L = next(train_data)\n",
    "                seq_len = np.max(L)\n",
    "\n",
    "                # For anomaly detection problem we reconstruct input data, so\n",
    "                # targets and inputs are identical.\n",
    "                feed_dict = {\n",
    "                    model.inputs: X,\n",
    "                    model.targets: X,\n",
    "                    model.lengths: L,\n",
    "                    model.dropout: self.dropout,\n",
    "                    model.batch_size: self.batch_size,\n",
    "                    model.max_seq_len: seq_len}\n",
    "                \n",
    "                fetches = [model.loss, model.decoder_outputs, model.train_optimizer]\n",
    "                step_loss, _, _ = sess.run(fetches, feed_dict)\n",
    "\n",
    "                total_loss.append(step_loss)\n",
    "                timings.append(timeit.default_timer() - beg_t)\n",
    "\n",
    "                if step % steps_per_epoch == 0:\n",
    "                    num_epoch += 1\n",
    "\n",
    "                if step % 200 == 0 or step == 1:\n",
    "                    print_progress(\n",
    "                        int(step / 200),\n",
    "                        num_epoch,\n",
    "                        np.mean(total_loss),\n",
    "                        np.mean(step_loss),\n",
    "                        np.sum(timings))\n",
    "                    timings = []\n",
    "\n",
    "                if step == 1:\n",
    "                    _ = tf.train.export_meta_graph(filename=self.path_to_graph + '.meta')\n",
    "                \n",
    "                if np.mean(total_loss) < min_loss or num_epoch > num_epochs:\n",
    "                    model.saver.save(sess, self.path_to_graph, global_step=step)\n",
    "                    print(\"Training is finished.\")\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(params)\n",
    "t = Trainer(params[\"batch_size\"], params[\"checkpoints\"], params[\"dropout\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (epoch 1), average_train_loss = 4.64368, step_loss = 4.64368, time_per_step = 0.190\n",
      "Step 1 (epoch 2), average_train_loss = 1.15463, step_loss = 0.61301, time_per_step = 3.102\n",
      "Step 2 (epoch 4), average_train_loss = 0.81288, step_loss = 0.31632, time_per_step = 3.016\n",
      "Step 3 (epoch 5), average_train_loss = 0.60371, step_loss = 0.09030, time_per_step = 3.042\n",
      "Step 4 (epoch 7), average_train_loss = 0.46817, step_loss = 0.04203, time_per_step = 3.062\n",
      "Step 5 (epoch 9), average_train_loss = 0.37997, step_loss = 0.02043, time_per_step = 3.054\n",
      "Step 6 (epoch 10), average_train_loss = 0.31906, step_loss = 0.01012, time_per_step = 3.011\n",
      "Training is finished.\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10 ** 6\n",
    "num_epochs = 60\n",
    "\n",
    "train_gen = d.train_generator(params[\"batch_size\"], num_epochs)\n",
    "train_size = d.train_size\n",
    "\n",
    "t.train(model, train_gen, train_size, num_steps, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the threshold setting is introduced. *Set_threshold* calculates the threshold value using *mean* and *std* of loss values of valid samples. \n",
    "\n",
    "At the testing stage, the model receives benign and anomalous samples.\n",
    "For each sample, the value of loss is calculated. If this value is greater than the threshold, then the request is considered anomalous.\n",
    "\n",
    "If you want to use special checkpoints without training a model, you can import a model from *params[\"checkpoint\"]* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor():\n",
    "    def __init__(self, checkpoints_path, std_factor, vocab):\n",
    "\n",
    "        self.threshold = 0.\n",
    "        self.checkpoints = checkpoints_path\n",
    "        self.path_to_graph = checkpoints_path + 'seq2seq'\n",
    "        self.std_factor = std_factor\n",
    "        self.vocab = vocab\n",
    "        self.__load()\n",
    "\n",
    "    def __load(self):\n",
    "        \"\"\"\n",
    "        Loads model from the checkpoint directory and sets models params. \n",
    "        \"\"\"\n",
    "        try:\n",
    "            loaded_graph = tf.Graph()\n",
    "            with loaded_graph.as_default():\n",
    "                saver = tf.train.import_meta_graph(\n",
    "                    self.path_to_graph + '.meta')\n",
    "\n",
    "            self.sess = tf.Session(graph=loaded_graph)\n",
    "            saver.restore(self.sess, tf.train.latest_checkpoint(\n",
    "                self.checkpoints))\n",
    "\n",
    "            # loading model parameters\n",
    "            self.inputs = loaded_graph.get_tensor_by_name('inputs:0')\n",
    "            self.targets = loaded_graph.get_tensor_by_name('targets:0')\n",
    "            self.lengths = loaded_graph.get_tensor_by_name('lengths:0')\n",
    "            self.dropout = loaded_graph.get_tensor_by_name('dropout:0')\n",
    "            self.batch_size_tensor = loaded_graph.get_tensor_by_name('batch_size:0')\n",
    "            self.seq_len_tensor = loaded_graph.get_tensor_by_name('max_seq_len:0')\n",
    "            self.get_batch_loss = loaded_graph.get_tensor_by_name('batch_loss:0')\n",
    "            self.get_probabilities = loaded_graph.get_tensor_by_name('probs:0')\n",
    "            self.get_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError('Unable to create model: {}'.format(e))\n",
    "\n",
    "    def set_threshold(self, data_gen):\n",
    "        \"\"\"\n",
    "        Calculates threshold for anomaly detection.\n",
    "        \"\"\"\n",
    "        \n",
    "        total_loss = []\n",
    "        for seq, l in data_gen:\n",
    "            batch_loss, _ = self._predict_for_request(seq, l)\n",
    "            total_loss.extend(batch_loss)\n",
    "\n",
    "        mean = np.mean(total_loss)\n",
    "        std = np.std(total_loss)\n",
    "        self.threshold = mean + self.std_factor * std\n",
    "\n",
    "        print('Validation loss mean: ', mean)\n",
    "        print('Validation loss std: ', std)\n",
    "        print('Threshold for anomaly detection: ', self.threshold)\n",
    "        \n",
    "        return self.threshold\n",
    "\n",
    "    def predict(self, data_gen, visual=True):\n",
    "        \"\"\"\n",
    "        Predicts probabilities and loss for given sequences.\n",
    "        \"\"\"\n",
    "        loss = []\n",
    "        predictions = []\n",
    "        num_displayed = 0\n",
    "        \n",
    "        for seq, l in data_gen:\n",
    "            batch_loss, alphas = self._predict_for_request(seq, l)\n",
    "            loss.extend(batch_loss)\n",
    "            alphas = self._process_alphas(seq, alphas, 1)\n",
    "            mask = np.array([l > self.threshold for l in batch_loss])\n",
    "            final_pred = mask.astype(int)\n",
    "            predictions.extend(final_pred)\n",
    "            \n",
    "            if visual and num_displayed < 10 and final_pred == [1]:\n",
    "                print('\\n\\nPrediction: ', final_pred[0])\n",
    "                print('Loss ', batch_loss[0])\n",
    "                \n",
    "                num_displayed += 1 \n",
    "                self._visual(alphas, seq)\n",
    "        \n",
    "        return predictions, loss\n",
    "\n",
    "    def _predict_for_request(self, X, l):\n",
    "        \"\"\"\n",
    "        Predicts probabilities and loss for given data. \n",
    "        \"\"\"\n",
    "        lengths = [l]\n",
    "        max_seq_len = l\n",
    "        feed_dict = {\n",
    "            self.inputs: X,\n",
    "            self.targets: X,\n",
    "            self.lengths: lengths,\n",
    "            self.dropout: 1.0,\n",
    "            self.batch_size_tensor: 1,\n",
    "            self.seq_len_tensor: max_seq_len}\n",
    "\n",
    "        fetches = [self.get_batch_loss, self.get_probabilities]\n",
    "        batch_loss, alphas = self.sess.run(fetches, feed_dict=feed_dict)\n",
    "\n",
    "        return batch_loss, alphas\n",
    "\n",
    "    def _process_alphas(self, X, alphas, batch_size):\n",
    "        \"\"\"\n",
    "        Counts numbers as probabilities for given data sample.\n",
    "        \"\"\"\n",
    "        processed_alphas = []\n",
    "        for i in range(batch_size):\n",
    "            probs = alphas[i]\n",
    "            coefs = np.array([probs[j][X[i][j]] for j in range(len(X[i]))])\n",
    "            coefs = coefs / coefs.max()\n",
    "            processed_alphas.append(coefs)\n",
    "            \n",
    "        return processed_alphas\n",
    "\n",
    "    def _visual(self, alphas, X):\n",
    "        \"\"\"\n",
    "        Colors sequence of malicious characters.\n",
    "        \"\"\"\n",
    "        for i, x in enumerate(X):\n",
    "            coefs = alphas[i]\n",
    "            tokens = self.vocab.int_to_string(x)\n",
    "            \n",
    "            for j in range(len(x)):\n",
    "                token = tokens[j]\n",
    "                if coefs[j] < 0.09:\n",
    "                    c = Fore.GREEN\n",
    "                else:\n",
    "                    c = Fore.BLACK\n",
    "                if token != '<PAD>' and token != '<EOS>':\n",
    "                    token = ''.join(c + token)\n",
    "                    print(token, end='')\n",
    "                    \n",
    "            print(Fore.BLACK + '', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/seq2seq-4805\n"
     ]
    }
   ],
   "source": [
    "p = Predictor(params[\"checkpoints\"], params[\"std_factor\"], params[\"vocab\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss mean:  5.2455907\n",
      "Validation loss std:  4.7683716e-07\n",
      "Threshold for anomaly detection:  5.245593547821045\n"
     ]
    }
   ],
   "source": [
    "val_gen = d.val_generator()\n",
    "threshold = p.set_threshold(val_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benign samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here FP samples are showed and FP rate is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = d.test_generator()\n",
    "valid_preds, valid_loss = p.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FP:  0\n",
      "Number of samples:  2200\n",
      "FP rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print('Number of FP: ', np.sum(valid_preds))\n",
    "print('Number of samples: ', len(valid_preds))\n",
    "print('FP rate: {:.4f}'.format(np.sum(valid_preds) / len(valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalous samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here TP samples are showed and TP rate is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1097 samples\n"
     ]
    }
   ],
   "source": [
    "pred_data = Data(path_anomaly_data, predict=True)\n",
    "pred_gen = pred_data.predict_generator()\n",
    "anomaly_preds, anomaly_loss = p.predict(pred_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TP:  0\n",
      "Number of samples:  1097\n",
      "TP rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print('Number of TP: ', np.sum(anomaly_preds))\n",
    "print('Number of samples: ', len(anomaly_preds))\n",
    "print('TP rate: {:.4f}'.format(np.sum(anomaly_preds) / len(anomaly_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results, let's compute metrics of quality: precision, recall, ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate(([0] * len(valid_preds), [1] * len(anomaly_preds)), axis=0)\n",
    "preds = np.concatenate((valid_preds, anomaly_preds), axis=0)\n",
    "loss_pred = np.concatenate((valid_loss, anomaly_loss), axis=0)\n",
    "assert len(y_true)==len(loss_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darklord/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true, preds)\n",
    "recall = recall_score(y_true, preds)\n",
    "print('Precision: {:.4f}'.format(precision))\n",
    "print('Recall: {:.4f}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73c252fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true, loss_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
